### PufferLib demo environments
# Package parameters override defaults.
# Parameters for specific envs override packages
# You cannot specify any deeper than that.
default:
  package: ~
  env_name: ~
  env: {}
  policy: {}
  use_rnn: False
  rnn: {}
  train:
    seed: 1
    torch_deterministic: True
    cpu_offload: False
    device: cuda
    total_timesteps: 10_000_000
    learning_rate: 2.5e-4
    num_steps: 128
    anneal_lr: True
    gamma: 0.99
    gae_lambda: 0.95
    num_minibatches: 4
    update_epochs: 4
    norm_adv: True
    clip_coef: 0.1
    clip_vloss: True
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
    target_kl: ~

    num_envs: 8
    num_workers: 8
    env_batch_size: ~
    zero_copy: True
    verbose: True
    data_dir: experiments
    checkpoint_interval: 200
    batch_size: 1024
    minibatch_size: 512
    bptt_horizon: 16
    vf_clip_coef: 0.1
    compile: False
    compile_mode: reduce-overhead

  sweep:
    method: random
    name: sweep
    metric:
      goal: maximize
      name: environment/episode_return
    # Nested parameters name required by WandB API
    parameters:
      train:
        parameters:
          learning_rate: {
            'distribution': 'log_uniform_values',
            'min': 1e-4,
            'max': 1e-1,
          }
          batch_size: {
            'values': [512, 1024, 2048],
          }
          minibatch_size: {
            'values': [128, 256, 512],
          }
          bptt_horizon: {
            'values': [4, 8, 16],
          }

### Arcade Learning Environment suite
# Convenience wrappers provided for common test environments
atari:
  env_name: BreakoutNoFrameskip-v4
beamrider:
  package: atari
  env_name: BeamRiderNoFrameskip-v4
beam_rider:
  package: atari
  env_name: BeamRiderNoFrameskip-v4
beam-rider:
  package: atari
  env_name: BeamRiderNoFrameskip-v4
breakout:
  package: atari
  env_name: BreakoutNoFrameskip-v4
enduro:
  package: atari
  env_name: EnduroNoFrameskip-v4
pong:
  package: atari
  env_name: PongNoFrameskip-v4
qbert:
  package: atari
  env_name: QbertNoFrameskip-v4
seaquest:
  package: atari
  env_name: SeaquestNoFrameskip-v4
spaceinvaders:
  package: atari
  env_name: SpaceInvadersNoFrameskip-v4
space_invaders:
  package: atari
  env_name: SpaceInvadersNoFrameskip-v4
space-invaders:
  package: atari
  env_name: SpaceInvadersNoFrameskip-v4

breakout-max-sync:
  package: atari
  env_name: BreakoutNoFrameskip-v4
  train:
    num_envs: 48
    num_workers: 24
    env_batch_size: 48
    zero_copy: False
    batch_size: 6144
    minibatch_size: 1536

breakout-max:
  package: atari
  env_name: BreakoutNoFrameskip-v4
  train:
    num_envs: 144 
    num_workers: 24
    env_batch_size: 48
    zero_copy: False
    batch_size: 18432
    minibatch_size: 4608

pong-max:
  package: atari
  env_name: PongNoFrameskip-v4
  train:
    num_envs: 96
    num_workers: 24
    env_batch_size: 48
    zero_copy: False
    batch_size: 65536
    minibatch_size: 2048
 
box2d:
  package: box2d

### Procgen Suite
# Shared hyperparams (best for all envs)
# Per-env hyperparams from CARBS
# Note: These need to be updated for 1.0
# batch sizes likely wrong
procgen:
  env_name: bigfish
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0005
    num_workers: 24
    num_envs: 144
    env_batch_size: 48
    batch_size: 16384
    minibatch_size: 5321
    gamma: 0.999
    update_epochs: 3
    anneal_lr: False
    clip_coef: 0.2
    vf_clip_coef: 0.2
  policy:
    cnn_width: 16
    mlp_width: 256
bigfish:
  package: procgen
  env_name: bigfish
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0001901266338648
    gamma: 0.9990684264891424
    ent_coef: 0.0025487710400836
    vf_coef: 1.1732211834792117
    gae_lambda: 0.8620630095238284
    clip_coef: 0.4104603426698214
    batch_size: 53210
    batch_rows: 5321
    bptt_horizon: 1
    update_epochs: 3
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 22
    mlp_width: 327
bossfight:
  package: procgen
  env_name: bossfight
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0001391202716783
    gamma: 0.9989348776761554
    ent_coef: 0.0141638234842547
    vf_coef: 2.3544979860388664
    gae_lambda: 0.8895733311775463
    clip_coef: 0.5642914060539239
    num_cores: 1
    num_envs: 1
    batch_size: 48520
    minibatch_size: 6065
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 34
    mlp_width: 83
caveflyer:
  package: procgen
  env_name: caveflyer
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0003922570060721
    gamma: 0.9974587177630908
    ent_coef: 0.0225727962984408
    vf_coef: 1.6255759569858712
    gae_lambda: 0.9094175213807228
    clip_coef: 0.4508383484491862
    batch_size: 32308
    minibatch_size: 8077
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 17
    mlp_width: 242
chaser:
  package: procgen
  env_name: chaser
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0003508035442326
    gamma: 0.9942435848334558
    ent_coef: 0.0071001859366116
    vf_coef: 2.1530812235373684
    gae_lambda: 0.8186838232115529
    clip_coef: 0.0821348744853704
    batch_size: 17456
    minibatch_size: 2182
    update_epochs: 1
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 37
    mlp_width: 198
climber:
  package: procgen
  env_name: climber
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0001217047694837
    gamma: 0.998084323380632
    ent_coef: 0.0171304566412224
    vf_coef: 0.8123888927054865
    gae_lambda: 0.8758003745828604
    clip_coef: 0.3879433119086241
    batch_size: 113288
    batch_rows: 3332 # ?
    bptt_horizon: 256
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 29
    mlp_width: 134
coinrun:
  package: procgen
  env_name: coinrun
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0002171100540455
    gamma: 0.9962953325196714
    ent_coef: 0.0024830293961112
    vf_coef: 0.4045225563446447
    gae_lambda: 0.9708900757395368
    clip_coef: 0.271239381520248
    batch_size: 184170
    minibatch_size: 6139
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 16
    mlp_width: 384
dodgeball:
  package: procgen
  env_name: dodgeball
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0002471773711262
    gamma: 0.9892421826991458
    ent_coef: 0.0061212242920176
    vf_coef: 0.905405768115384
    gae_lambda: 0.929215062387182
    clip_coef: 0.1678680070658446
    batch_size: 233026
    minibatch_size: 4958
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 24
    mlp_width: 538
fruitbot:
  package: procgen
  env_name: fruitbot
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0005426317191531
    gamma: 0.9988953819963396
    ent_coef: 0.0115430852027873
    vf_coef: 0.5489566038515201
    gae_lambda: 0.7517437269156811
    clip_coef: 0.3909436413913963
    batch_size: 25344
    minibatch_size: 4224
    update_epochs: 1
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 24
    mlp_width: 600
heist:
  package: procgen
  env_name: heist
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0001460588554421
    gamma: 0.9929899907866796
    ent_coef: 0.0063411167117336
    vf_coef: 1.3750495866441763
    gae_lambda: 0.864713026766495
    clip_coef: 0.0341243664433126
    batch_size: 162233
    minibatch_size: 3061
    update_epochs: 1
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 60
    mlp_width: 154
jumper:
  package: procgen
  env_name: jumper
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0002667825838749
    gamma: 0.996178793124514
    ent_coef: 0.0035712927399072
    vf_coef: 0.2066134576246479
    gae_lambda: 0.9385007945498072
    clip_coef: 0.0589308261206342
    batch_size: 76925
    minibatch_size: 3077
    update_epochs: 3
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 24
    mlp_width: 190
leaper:
  package: procgen
  env_name: leaper
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.000238551194954
    gamma: 0.9984543257393016
    ent_coef: 0.0264785452036158
    vf_coef: 1.12387183485305
    gae_lambda: 0.8968331903476625
    clip_coef: 0.6941033332120052
    batch_size: 19380
    minibatch_size: 6460
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 28
    mlp_width: 100
maze:
  package: procgen
  env_name: maze
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0001711754945436
    gamma: 0.9986484783565428
    ent_coef: 0.0027020733255912
    vf_coef: 0.1236421145384316
    gae_lambda: 0.971943769322524
    clip_coef: 0.2335644352369076
    batch_size: 116008
    minibatch_size: 6834
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 28
    mlp_width: 526
miner:
  package: procgen
  env_name: miner
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.000328692228852
    gamma: 0.990897931823388
    ent_coef: 0.0045505824544649
    vf_coef: 6.559292234163336
    gae_lambda: 0.6494040942916905
    clip_coef: 0.2293978935956241
    batch_size: 154512
    minibatch_size: 2088
    update_epochs: 3
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 38
    mlp_width: 175
ninja:
  package: procgen
  env_name: ninja
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0002649776171804
    gamma: 0.998357586821043
    ent_coef: 0.0077158486367147
    vf_coef: 2.171674659769069
    gae_lambda: 0.9664148604540898
    clip_coef: 0.5891635585927152
    batch_size: 45246
    minibatch_size: 7541
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 25
    mlp_width: 317
plunder:
  package: procgen
  env_name: plunder
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0002630139944456
    gamma: 0.9981502407071172
    ent_coef: 0.0222691283544936
    vf_coef: 4.316832667738928
    gae_lambda: 0.84500339385464
    clip_coef: 0.0914132500563203
    batch_size: 26304
    minibatch_size: 4384
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 30
    mlp_width: 288
starpilot:
  package: procgen
  env_name: starpilot
  train:
    total_timesteps: 8_000_000
    learning_rate: 0.0004257280551714
    gamma: 0.9930510505613882
    ent_coef: 0.007836164188961
    vf_coef: 5.482314699746532
    gae_lambda: 0.82792978724664
    clip_coef: 0.2645124138418521
    batch_size: 107440
    minibatch_size: 6715
    update_epochs: 2
    anneal_lr: False
    vf_clip_coef: 0.2
  policy:
    cnn_width: 25
    mlp_width: 144

bsuite:
  package: bsuite
  env_name: bandit/0
  train:
    total_timesteps: 1_000_000
    num_envs: 1

butterfly:
  package: butterfly
  env_name: cooperative_pong_v5

classic_control:
  env_name: cartpole
  train:
    total_timesteps: 500_000
    num_envs: 64
classic-control:
  package: classic_control
classiccontrol:
  package: classic_control
cartpole:
  package: classic_control

crafter:
  package: crafter
  env_name: CrafterReward-v1
  train:
    num_envs: 96
    num_workers: 24
    env_batch_size: 48 
    zero_copy: False
    batch_size: 6144
    compile: True

dm_control:
  package: dm_control
dm-control:
  package: dm_control
dmcontrol:
  package: dm_control
dmc:
  package: dm_control

dm_lab:
  package: dm_lab
dm-lab:
  package: dm_lab
dmlab:
  package: dm_lab
dml:
  package: dm_lab

griddly:
  package: griddly
  env_name: GDY-Spiders-v0

magent:
  package: magent
  env_name: battle_v4

microrts:
  env_name: GlobalAgentCombinedRewardEnv

minerl:
  env_name: MineRLNavigateDense-v0

minigrid:
  env_name: MiniGrid-LavaGapS7-v0
  train:
    total_timesteps: 1_000_000
    num_envs: 48
    num_workers: 6
    env_batch_size: 48
    batch_size: 6144
    minibatch_size: 768
    ent_coef: 0.05
    anneal_lr: False

minihack:
  env_name: MiniHack-River-v0
  train:
    num_envs: 48
    num_workers: 24
    env_batch_size: 48
    zero_copy: False
    batch_size: 6144
    minibatch_size: 1536

nethack:
  env_name: NetHackScore-v0
  train:
    num_envs: 72
    num_workers: 24
    env_batch_size: 48
    zero_copy: False
    batch_size: 6144
    update_epochs: 1
    compile: False

nmmo:
  train:
    num_envs: 1
    num_workers: 1
    batch_size: 4096
    minibatch_size: 2048

nmmo3:
  use_rnn: True
  train:
    total_timesteps: 10_000_000
    #total_timesteps: 10_000_000_000
    num_envs: 72
    num_workers: 24
    env_batch_size: 24
    update_epochs: 1
    gamma: 0.998
    #batch_size: 32768
    batch_size: 196608
    minibatch_size: 16384
    #compile: True
  env:
    num_envs: 1 # NMMO3 provides its own fast multienv
    #num_envs: 8 # NMMO3 provides its own fast multienv
    #
nmmo3laptop:
  package: nmmo3
  policy:
    inference_batch_size: 4096
    train_batch_size: 16384
  train:
    total_timesteps: 10_000_000
    num_envs: 24
    num_workers: 6
    env_batch_size: 8
    update_epochs: 1
    gamma: 0.998
    batch_size: 32768
    minibatch_size: 16384
    #compile: True
    compile: False

nmmo3debug:
  package: nmmo3
  policy:
    inference_batch_size: 512
    train_batch_size: 8192
  train:
    total_timesteps: 10_000_000
    num_envs: 1
    num_workers: 1
    env_batch_size: 1
    update_epochs: 1
    gamma: 0.998
    #ent_coef: 0.05
    batch_size: 8192
    minibatch_size: 8192
    compile: False
  sweep:
    method: random
    name: sweep
    metric:
      goal: maximize
      name: environment/reward_dist
    # Nested parameters name required by WandB API
    parameters:
      train:
        parameters:
          gamma: {
            'values': [0.95, 0.975, 0.99, 0.995, 0.998],
          }
          learning_rate: {
            'distribution': 'log_uniform_values',
            'min': 1e-4,
            'max': 1e-1,
          }
          batch_size: {
            'values': [8192, 16384, 32768],
          }
          bptt_horizon: {
            'values': [4, 8, 16],
          }



# Ocean: PufferAI's first party environment suite
ocean:
  env_name: squared
  use_rnn: True
  train:
    total_timesteps: 30_000
    learning_rate: 0.017
    num_envs: 8
    num_workers: 2
    env_batch_size: 8
    minibatch_size: 128
    bptt_horizon: 4
    device: cpu
bandit:
  package: ocean
memory:
  package: ocean
multiagent:
  package: ocean
password:
  package: ocean
performance:
  package: ocean
spaces:
  package: ocean
squared:
  package: ocean
stochastic:
  package: ocean

open_spiel:
  env_name: connect_four
  train:
    num_envs: 32
    batch_size: 4096
open-spiel:
  package: open_spiel
openspiel:
  package: open_spiel
connect_four:
  package: open_spiel
  env_name: connect_four
connect-four:
  package: open_spiel
  env_name: connect_four
connectfour:
  package: open_spiel
  env_name: connect_four
connect4:
  package: open_spiel
  env_name: connect_four

pokemon_red:
  use_rnn: True
  train:
    total_timesteps: 1_000_000
    num_envs: 96 
    num_workers: 24
    env_batch_size: 32
    zero_copy: False
    update_epochs: 3
    gamma: 0.998
    batch_size: 65536
    minibatch_size: 2048
    compile: True
    learning_rate: 2.0e-4
    anneal_lr: False
pokemon-red:
  package: pokemon_red
pokemonred:
  package: pokemon_red
pokemon:
  package: pokemon_red
pokegym:
  package: pokemon_red
pokedebug:
  package: pokemon_red
  train:
    num_envs: 4
    num_workers: 4
    env_batch_size: 2
    batch_size: 2048
    minibatch_size: 256
    compile: True
 
links_awaken:
  package: links_awaken
links-awaken:
  package: links_awaken
linksawaken:
  package: links_awaken
zelda:
  package: links_awaken

smac: {}
starcraft:
  package: smac

stable_retro:
  env_name: Airstriker-Genesis
stable-retro:
  package: stable_retro
stableretro:
  package: stable_retro
retro:
  package: stable_retro
