![figure](https://pufferai.github.io/build/html/_images/header.png)

[![Discord Chat](https://img.shields.io/discord/569049269051457537.svg)](https://discord.gg/spT4huaGYV)
<a href="https://twitter.com/jsuarez5341?ref_src=twsrc%5Etfw" target="_blank">
  <img src="http://jpillora.com/github-twitter-button/img/tweet.png"
       alt="tweet button" title="Follow"></img>
</a>

You have an environment, a PyTorch model, and a reinforcement learning framework that are designed to work together but donâ€™t. PufferLib is a wrapper layer that makes RL on complex game environments as simple as RL on Atari. You write a native PyTorch network and a short binding for your environment; PufferLib takes care of the rest.

All of our [Documentation](https://pufferai.github.io "PufferLib Documentation") is hosted by github.io. @jsuarez5341 on [Discord](https://discord.gg/spT4huaGYV) for support -- post here before opening issues. I am also looking for contributors interested in adding bindings for other environments and RL frameworks.
